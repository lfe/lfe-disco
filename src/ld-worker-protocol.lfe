(defmodule ld-worker-protocol
  (export all))

(include-lib "ldisco/include/ld-worker-protocol.lfe")

(defun max-message-length () (* 100 1024 1024))

(defun encode (name)
  (encode name ""))

(defun encode (name payload)
  (let* ((type (list_to_binary name))
         ;; XXX change to use ljson instead of jiffy once ljson is ready
         (body (ljson:encode payload))
         (length (list_to_binary (integer_to_list (byte_size body)))))
    (binary (type binary) " " (length binary) " " (body binary) "\n")))

(defun decode (data)
  (let ((`#(ok #(,type ,body) ,_ ,_) (parse data)))
    (list (binary_to_list type) (ljson:decode body))))

;;; The following functions are intended for use by a worker implementation
;;; that is sending messages to Disco.
;;;

(defun start (version pid)
  "Announce the startup of the worker.

  The payload is a dictionary containing the following information:
  * version   The version of the message protocol the worker is using, as a
                string.
  * pid       The integer pid of the worker.

  The worker should send this so it can be properly killed, (e.g. if there’s a
  problem with the job). This is currently required due to limitations in the
  Erlang support for external spawned processes.

  The worker should send a WORKER message before it sends any others. Disco
  should respond with an OK if it intends to use the same version."
  ;; Usage:
  ;;
  ;; > (set data (ld-worker-protocol:start 'pidname))
  ;; #B(87 79 82 75 69 82 32 51 56 32 123 34 118 101 114 ...)
  ;; > (ljson:print (ld-worker-protocol:decode data))
  ;; ["WORKER",[{<<"version">>,"1.1"},{<<"pid">>,<<"pidname">>}]]
  ;; ok
  ;; >
  (encode "WORKER" `(#(version ,version) #(pid ,pid))))

(defun start (pid)
  (start "1.1" pid))

(defun request-task-info ()
  "Request the task information from Disco.

  The worker should send a TASK message with no payload. A worker
  implementation would then need to await a message from Disco and use
  the (parse-task-info ...) call on the returned data."
  ;; Usage:
  ;;
  ;; > (set data (ld-worker-protocol:request-task-info))
  ;; #B(84 65 83 75 32 50 32 91 93 10)
  ;; > (ljson:print (ld-worker-protocol:decode data))
  ;; ["TASK",[]]
  ;; ok
  ;; >
  (encode "TASK"))

(defun request-inputs ()
  "Request input for the task from Disco.

  To get the complete list of current inputs for the task, the worker can send
  an INPUT message with no payload. A worker implementation would then need to
  await a message from Disco and use the (parse-inputs ...) call on the
  returned data."
  (encode "INPUT"))

(defun input-err (input-id replica-ids)
  "Inform Disco about failures in retrieving inputs.

  The worker should inform Disco if it cannot retrieve an input due to
  failures accessing the replicas specified by Disco in the INPUT
  response. The payload of this message specifies the input and the
  failed replica locations using their identifiers, as follows:

    [input_id, [rep_id]]

  If there are alternative replicas that the worker can try, Disco should
  respond with a RETRY message, with a payload specifying new replicas:

    [[rep_id, replica_location]]

  If there are no alternatives, and it is not possible for Disco to
  generate new alternatives, Disco should reply with a FAIL message
  (which has no payload).

  If Disco is in the process of generating new replicas, it should reply
  with a WAIT message and specify an integer duration in seconds in the
  payload. The worker should then poll for any new replicas after the
  specified duration."
  (encode "INPUT_ERR" `(,input-id ,replica-ids)))

(defun text-message (string-data)
  "Send a message to Disco (i.e. to be displayed in the ui).

  The worker can send a MSG message, with a payload containing a string.
  Disco should respond with an OK."
  (encode "MSG" string-data))

(defun report-outputs (label output-location output-size)
  "The worker should report its output(s) to Disco.

  For each output generated by the worker, it should send an OUTPUT message
  specifying the type and location of the output, and its label:

    [label, output-location, output-size]

  Local outputs have locations that are paths relative to jobhome."
  (encode "OUTPUT" `(,label ,output-location ,output-size)))

(defun done (payload)
  "Inform Disco that the worker is finished.

  The worker should only send this message (which has no payload) after
  syncing all output files, since Disco normally terminates the worker
  when this message is received. The worker should NOT exit immediately
  after sending this message, since there is no guarantee if the message
  will be received by Disco if the worker exits. Instead, the worker
  should wait for the response from Disco (as it should for all messages)."
  (encode "DONE"))

(defun error (error-string)
  "Report a failed input or transient error to Disco.

  The worker can send a ERROR message with a payload containing the error
  message as a string. This message will terminate the worker, but not
  the job. The current task will be retried by Disco. See also the
  information above for the DONE message."
  (encode "ERROR" error-string))

(defun fatal (error-string)
  "Report a fatal error to the master.

  The worker can send an FATAL message, with a payload containig the
  error message as a string. This message will terminate the entire job.
  See also the information above for the DONE message."
  (encode "FATAL" error-string))

(defun ping (payload)
  "No-op - always returns OK.

  Worker can use PING as a heartbeat message, to make sure that the master
  is still alive and responsive."
  (encode "PING" payload))

;;; The following functions are intended for use by a worker implementation
;;; that is receiving messages from Disco.
;;;
(defun parse-ok (payload)
  "A generic response from Disco. This message has the payload 'ok'."
  (encode "OK" payload))

(defun parse-fail (payload)
  "A possible response from Disco for an INPUT_ERR message, as described
  above."
  (encode "FAIL" payload))

(defun parse-retry (payload)
  "A possible response from Disco for an INPUT_ERR message, as described
  above."
  (encode "RETRY" payload))

(defun parse-wait (payload)
  "A possible response from Disco for an INPUT_ERR message, as described
  above."
  (encode "WAIT" payload))

(defun parse-task-info (payload)
  "When a worker issues the (request-task-info) call, Disco should respond
  with a TASK message, and a payload containing the following task information
  as a list of tuples:

  * host       The host the task is running on.
  * master     The host the master is running on.
  * jobname    The name of the job this task is a member of.
  * taskid     The internal Disco id of the task.
  * stage      The stage of the pipeline this task belongs to.
  * grouping   The grouping specified in the pipeline for the above stage.
  * group      The group this task will get its inputs from, as computed by
                 the grouping. This is a tuple consisting of an integer label
                 and a host name. Note that due to re-executions, this host
                 name may not match the value in the above “host” field.
  * disco_port The value of the DISCO_PORT setting, which is the port the
                 Disco master is running on, and the port used to retrieve
                 data from Disco and DDFS. This is used to convert URLs with
                 the disco and ddfs schemes into http URLs.
  * put_port   The value of the DDFS_PUT_PORT setting. This can be used by
                 the worker to upload results to DDFS.
  * disco_data The value of the DISCO_DATA setting.
  * ddfs_data  The value of the DDFS_DATA setting. This can be used to read
                 DDFS data directly from the local filesystem after it has
                 been ascertained that the DDFS data is indeed local to the
                 current host.
  * jobfile    The path to the The Job Pack file for the current job. This
                 can be used to access any Additional Job Data that was
                 uploaded as part of the The Job Pack."
  (let ((`(,_ ,data) (decode payload)))
    data))

(defun parse-inputs (payload)
  "When a worker issues the (request-inputs) call, Disco should respond with
  an INPUT message, and a payload containing a two-element tuple (list in
  JSON).

  The first element is a flag, which will either be ‘more’ or ‘done’. ‘done’
  indicates that the input list is complete, while ‘more’ indicates that more
  inputs could be added to the list in the future, and the worker should
  continue to poll for new inputs.

  The second element is a list of inputs, where each input is a specified as
  a four-element tuple:

    #(input_id status label replicas)

  where input_id is an integer identifying the input, label is the label
  attached to the input, and status and replicas follow the format:

    status ::= 'ok' | 'busy' | 'failed'
    replicas ::= [replica]
    replica ::= rep_id, replica_location

  It is possible for an input to be available at multiple locations; each
  such location is called a replica. A rep_id is an integer identifying
  the replica.

  The replica_location is specified as a URL. The protocol scheme used for
  the replica_location could be one of http, disco, dir or raw. A URL with
  the disco scheme is to be accessed using HTTP at the disco_port specified
  in the TASK response from Disco. The raw scheme denotes that the URL
  itself (minus the scheme) is the data for the task. The data needs to be
  properly URL encoded, for instance using Base64 encoding. The dir is like
  the disco scheme, except that the file pointed to contains lines of the
  form

    <label> ‘SP’ <url> ‘SP’ <output_size> ‘\n’

  The ‘label’ comes from the ‘label’ specified in an OUTPUT message by a
  task, while the ‘url’ points to a file containing output data generated
  with that label. The ‘output_size’ specifies the size of the output file.

  This is currently how labeled output data is communicated by upstream
  tasks to downstream ones in the Disco pipeline.

  One important optimization is to use the local filesystem instead of HTTP
  for accessing inputs when they are local. This can be determined by
  comparing the URL hostname with the host specified in the TASK response,
  and then converting the URL path into a filesystem path using the
  disco_data or ddfs_data path prefixes for URL paths beginning with disco/
  and ddfs/ respectively.

  The common input status will be ‘ok’ - this indicates that as far as Disco
  is aware, the input should be accessible from at least one of the
  specified replica locations. The ‘failed’ status indicates that Disco
  thinks that the specified locations are inaccessible; however, the worker
  can still choose to ignore this status and attempt retrieval from the
  specified locations. A ‘busy’ status indicates that Disco is in the
  process of generating more replicas for this input, and the worker
  should poll for additional replicas if needed.

  It is recommended that the worker attempts the retrieval of an input from
  the replica locations in the order specified in the response. That is, it
  should attempt retrieval from the first replica, and if that fails, then
  try the second replica location, and so on.

  When a worker polls for any changes in task’s input, it is preferable not
  to repeatedly retrieve information for inputs already successfully
  processed. In this case, the worker can send an INPUT message with an
  ‘exclude’ payload that specifies the input_ids to exclude in the
  response. In this case, the INPUT message from the worker should have
  the following payload:

    ['exclude', [input_id]]

  On the other hand, when a worker is interested in changes in replicas for
  a particular set of inputs, it can send an INPUT message with an
  include payload that requests information only for the specified
  input_ids. The INPUT message from the worker in this case should have
  the following payload:

    ['include', [input_id]]"
  )
